<!DOCTYPE html>
<html lang="zh">

<head>
    <meta charset="UTF-8">
    <title>RavelloH’s Blog | Python实现网络爬虫</title>
    <meta name="keywords" content="RavelloH,blog,python,spider,html">
    <meta name="description" content="A Blog by RavelloH">

    <!-- CSS -->
    <link type="text/css" rel="stylesheet" href="/css/common.css">
    <link type="text/css" rel="stylesheet" href="/css/style.css">
    <link type="text/css" rel="stylesheet" href="/css/iconfont.css">


    <!-- JavaScript -->
    <script type="text/javascript" src="/js/loading.js"></script>
    <script type="text/javascript" src="/js/common.js"></script>
    <script>
            var img = [];
            var flag = 0;
            var mulitImg = ['http://ravelloh.github.io/article/20220323/img1.jpg'];
            var imgTotal = mulitImg.length;  //图片总数
            for(var i = 0 ; i < imgTotal ; i++){
    img[i] = new Image()
    img[i].src = mulitImg[i]
    img[i].onload = function(){
      //document.getElementsByID('loadingtext')[0].appendChild(this)  
      // console.log(this.width)
      flag++;
      if( flag == imgTotal ){
         document.getElementById("loadingtext").innerHTML = "*文章插图加载完成:1/1";
      }
    }
 }
       </script>
</head>

<body>

    <body>

        <section class="showcase">
            <header>
                <h2 class="logo">
                    <a href="/">
                        <img class="logoimg" src="/img/avatar.jpg" style="width: 1.5em;border-radius: 50%;" alt="avatar">
                        <img class="logoimg" src="/img/RavelloH.svg" alt="RavelloH's Blog">
                    </a>

                </h2>
                <div class="headers">
                    <nav>
                        <a href="/">
                            HOME
                        </a>
                        <a href="/works/">
                            WORKS
                        </a>
                        <a href="/articles/">
                            ARTICLES
                        </a>
                        <a href="/tag/">
                            TAG
                        </a>
                        <a href="/about/">
                            ABOUT
                        </a>
                        </p>
                    </nav>
                </div>
                <div class="toggle" class="header">
                </div>
            </header>

            <div class="overlay"></div>
            <div class="article" id="text">
                <div id="scroll-progress"></div>
                <h2>Python实现网络爬虫</h2>
                <span class="iconfontmini icon-clock"></span> 2022-03-23 · <span
                    class="iconfontmini icon-classification"></span>
                    <a href="/classification/#技术">技术</a>·
                    <span class="iconfontmini icon-tag"></span> 
                    <a class="tag" href="/tag/#python">PYTHON</a>
                    <a class="tag" href="/tag/#spider">SPIDER</a>
                    <div>
                    <h4><b><em>Menu - 目录列表</em></b></h4>
                    <a class="m" href="#前言">前言</a>
                    <a class="m" href="#效果">效果</a>
                    <a class="m" href="#实现方式">实现方式</a>
                    <a class="m" href="#代码">代码</a>
                    <a class="m" href="#下载">下载</a>
                </div>
                <hr>
                <br><br>
                <div class="center"><em>
                        <a id="loadingtext">*当前文章正在加载插图:0/1</a>
                    </em>
                </div>
                <br>
                <h4><a name="前言" href="#前言">#前言</a></h4>
                <p>
                最近在参与一个数据收集的项目，需要大量获取图像及链接等，用人力显然是完成不过来了，<br>
                于是索性就做个爬虫，一劳永逸了。<br>
                这里因为项目比较小，对效率要求不大，就选择了使用Python而不是C语言。<br>
                </del>(也因为Python用起来更省事)</del><br>
                本文所含代码可直接跳转<a class="m" href="#代码">#代码</a>查看
                </p>
                <br>
                <h4><a name="效果" href="#效果">#效果</a></h4>
                <img class="img" id="img1" src="img1.jpg">
                <p>
                    效果如上图，即输入网页链接，自动提取所含图片链接，<br>
                    同时自动转化相对路径为绝对路径，方便下载。<br>
                    最后每行一个print出来，方便统一存储/下载。<br>
                    <br>
                </p>
                <h4><a name="实现方式" href="#实现方式">#实现方式</a></h4>
                <p>
                    Python在爬虫方面已经十分成熟，这里引用第三方库BeautifulSoup与urllib，若无这些库请下载:
                </p>
                    <pre>
                    <span>pip install bs4</span>
                    <span>pip install urllib</span>
                    </pre>
                    <em>*命令行执行即可</em>
                    <br>
                <p>依赖库准备完后，引用：</p>
                    <pre>
                    <span>from urllib.request import urlopen,build_opener,ProxyHandler</span>
                    <span>from bs4 import BeautifulSoup as bf</span>
                    <span>from urllib import request</span>
                    <span>import random</span>
                    </pre>
                 <p>此处引用random以及build_opener与ProxyHandler是为了后续反爬，<br>
                    <del>(毕竟默认UA是Python.Urllib)</del><br>
                    接着配置UA池与IP代理池，防止被反爬(若项目规模较小可忽略此步)
                 </p>
                    <pre>
                    <span># UA</span>
                    <span>user_agent_list = [</span>
                    <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10.6;rv:2.0.1)Gecko/20100101Firefox/4.0.1",</span>
                    <span>    "Mozilla/4.0(compatible;MSIE6.0;WindowsNT5.1)",</span>
                    <span>    "Opera/9.80(WindowsNT6.1;U;en)Presto/2.8.131Version/11.11",</span>
                    <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11",</span>
                    <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1)",</span>
                    <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)"</span>
                    <span>]</span>
                    <span># 随机UA</span>
                    <span>headers ={</span>
                    <span>    'User-Agent':random.choice(user_agent_list) ## 随机抽取UA</span>
                    <span>}</span>
                    <span></span>
                    <span>ip_list=[</span>
                    <span>    '125.120.62.26', ##IP池</span>
                    <span>    '66.249.93.118'</span>
                    <span>]</span>
                    <span></span>
                    <span># IP</span>
                    <span>ip={</span>
                    <span>    'http':random.choice(ip_list) ##随机抽取IP</span>
                    <span>}</span>
                    <span>link = input("在此输入网址:http://")</span>
                    <span>htmlurl = "https://"+str(link) #链接整合，若input中输入了带http头的链接可忽略此行</span>
                    <span>req = request.Request(htmlurl,headers=headers) #请求整合</span>
                    </pre>
                    <p>其中，ip_list推荐使用<a href="https://github.com/jhao104/proxy_pool" class="linkline">Github@jhao104/proxy_pool</a>开源的IP代理池。<sup><em>*代码中所列IP均为演示作用，若需应用请自行设置</em></sup><br>
                    在此就完成了UA与IP的随机分配，反爬基本完成<br>
                    <strong>不过反爬归反爬，也请自觉遵守robot协议，合理利用爬虫</strong>
                    下一步，发出请求：</p>
                    <pre>
                    <span># 用ProxyHandler创建代理ip对象</span>
                    <span>pro_han = ProxyHandler(ip)</span>
                    <span># 使用build_opener替代urlopen()创建一个对象</span>
                    <span>opener = build_opener(pro_han)</span>
                    <span># 发送请求</span>
                    <span>res = opener.open(req)</span>
                    </pre>
                    <p>到这里为止，整个请求结束，之后用BeautifulSoup解析:</br>
                    <em>*下面已用bs代指beautifulsoup</em>
                    </p>
                    <pre>
                    <span>obj = bf(res.read(),'html.parser') #解析html</span>
                    <span>title = str(obj.head.title) #获取标题</span>
                    <span>print("站点标题:",title,"正在查找图片")</span>
                    <span>pic_info = obj.find_all('img') #查询img标签</span>
                    </pre>
                    <p>
                    这里也给出不含反爬的请求：
                    (基本同上，唯一的区别是直接用urlopen打开链接)
                    </p>
                    <pre>
                    <span>html = urlopen("https://"+link)</span>
                    <span>obj = bs(html.read(),'html.parser') #解析html</span>
                    <span>title = str(obj.head.title) #获取标题</span>
                    <span>print("站点标题:",title,"正在查找图片")</span>
                    <span>pic_info = obj.find_all('img') #查询img标签</span>
                    </pre>
                    <p>
                    到这里我们已经成功将网页中所含的所有img标签以列表形式存储在了变量pic_info中，<br>
                    接下来遍历输出即可：
                    </p>
                    <pre>
                    <span>j = 0 #配置遍历</span>
                    <span>for i in pic_info:</span>
                    <span>    j += 1</span>
                    <span>    pic = str(i['src']) #转为字符串，方便查询</span>
                    <span>    if "http" not in pic: #检测http头</span>
                    <span>        if "data" in pic: #检测是否为DataURIScheme</span>
                    <span>            continue</span>
                    <span>        else:</span>
                    <span>            if "//" in pic: #格式补全</span>
                    <span>                print("http:"+pic) </span>
                    <span>            else:</span>
                    <span>                if pic[0] == "/": #适配相对路径</span>
                    <span>                    print("http://"+link+pic)    </span>
                    <span>                else:</span>
                    <span>                    print("http://"+link+"/"+pic) </span>
                    <span>            </span>
                    <span>    else:</span>
                    <span>        print(pic) #直接print绝对路径</span>
                    </pre>
                    <p>
                    上图套了四个if-else，作用分别是检测是否有http头、是否为内嵌base64图片、是否以//简写路径、是否使用相对路径，<br>
                    到这里为止，整个程序就结束了<br>
                    整个示例程序可分为引用-配置-请求-分析-输出5个部分，<br>
                    除了爬取图片，也可将上面的<code>pic_info = obj.find_all('img')</code>改成其他标签，<br>
                    比如改成meta可爬取简介，也可在特定站点内通过zaifind_all内添加对应的class(class_="xxx")及id(id_="xxx")来获取对应标签内的信息，<br>
                    实现更多功能。
                    </p>
                <h4><a name="代码" href="#代码">#代码</a></h4>
                <p>完整版</p>
                <pre>
                <span>from urllib.request import urlopen,build_opener,ProxyHandler</span>
                <span>from bs4 import BeautifulSoup as bf</span>
                <span>from urllib import request</span>
                <span>import random</span>
                <span></span>
                <span># UA</span>
                <span>user_agent_list = [</span>
                <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10.6;rv:2.0.1)Gecko/20100101Firefox/4.0.1",</span>
                <span>    "Mozilla/4.0(compatible;MSIE6.0;WindowsNT5.1)",</span>
                <span>    "Opera/9.80(WindowsNT6.1;U;en)Presto/2.8.131Version/11.11",</span>
                <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11",</span>
                <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1)",</span>
                <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)"</span>
                <span>]</span>
                <span># 随机UA</span>
                <span>headers ={</span>
                <span>    'User-Agent':random.choice(user_agent_list)</span>
                <span>}</span>
                <span></span>
                <span>ip_list=[</span>
                <span>    '209.97.171.128',</span>
                <span>    '114.250.25.19',</span>
                <span>    '125.120.62.26',</span>
                <span>    '66.249.93.118',</span>
                <span>    '1.202.113.240',</span>
                <span>]</span>
                <span></span>
                <span># IP</span>
                <span>ip={</span>
                <span>    'http':random.choice(ip_list)</span>
                <span>}</span>
                <span>link = input("在此输入网址:http://")</span>
                <span>htmlurl = "https://"+str(link)</span>
                <span>req = request.Request(htmlurl,headers=headers)</span>
                <span></span>
                <span># 创建代理ip对象</span>
                <span>pro_han = ProxyHandler(ip)</span>
                <span># 使用build_opener创建一个对象</span>
                <span>opener = build_opener(pro_han)</span>
                <span># 发送请求</span>
                <span>res = opener.open(req)</span>
                <span>obj = bf(res.read(),'html.parser') #解析html</span>
                <span>title = str(obj.head.title)</span>
                <span>print("站点标题:",title,"正在查找图片")</span>
                <span>pic_info = obj.find_all('img')</span>
                <span>j = 0 #配置遍历</span>
                <span>for i in pic_info:</span>
                <span>    j += 1</span>
                <span>    pic = str(i['src'])</span>
                <span>    if "http" not in pic:</span>
                <span>        if "data" in pic:</span>
                <span>            continue</span>
                <span>        else:</span>
                <span>            if "//" in pic:</span>
                <span>                print("http:"+pic) </span>
                <span>            else:</span>
                <span>                if pic[0] == "/":</span>
                <span>                    print("http://"+link+pic)    </span>
                <span>                else:</span>
                <span>                    print("http://"+link+"/"+pic) </span>
                <span>            </span>
                <span>    else:</span>
                <span>        print(pic)</span>
                </pre>
                
                <br>
                <p>基础版</p>
                <pre>
                <span>from urllib.request import urlopen</span>
                <span>from bs4 import BeautifulSoup as bs</span>
                <span>link = input("在此输入网址:http://")</span>
                <span>html = urlopen("https://"+link)</span>
                <span>obj = bs(html.read(),'html.parser') #解析html</span>
                <span>title = str(obj.head.title)</span>
                <span>print("站点标题:",title,"正在查找图片")</span>
                <span>pic_info = obj.find_all('img')</span>
                <span>j = 0 #配置遍历</span>
                <span>for i in pic_info:</span>
                <span>    j += 1</span>
                <span>    pic = str(i['src'])</span>
                <span>    if "http" not in pic:</span>
                <span>        if "data" in pic:</span>
                <span>            continue</span>
                <span>        else:</span>
                <span>            if "//" in pic:</span>
                <span>                print("http:"+pic) </span>
                <span>            else:</span>
                <span>                if pic[0] == "/":</span>
                <span>                    print("http://"+link+pic)    </span>
                <span>                else:</span>
                <span>                    print("http://"+link+"/"+pic) </span>
                <span>            </span>
                <span>    else:</span>
                <span>        print(pic)</span>
                </pre>
                
                <h4><a name="下载" href="#下载">#下载</a></h4>
                <p>此文章共含2个附件，分别对应 基础版 与 完整版 。</p><br>
                <p>imgspider.py - 0.73kb       <a href="https://raw.githubusercontent.com/RavelloH/download/main/code/imgspider.py">预览</a> | <a href="https://ravelloh.github.io/download/code/imgspider.py">下载</a></p><br>
                <p>imgspider-pro.py - 1.76kb   <a href="https://raw.githubusercontent.com/RavelloH/download/main/code/imgspider-pro.py">预览</a> | <a href="https://ravelloh.github.io/download/code/imgspider-pro.py">下载</a>
                </p>

                <hr>
                <br>
                <span class="iconfontmini icon-aboutcircle"></span> 原创内容使用 知识共享 署名-非商业性使用-相同方式共享 4.0 (CC BY-NC-ND 4.0)
                协议授权。

                <script src="https://utteranc.es/client.js" repo="ravelloh/utterances" issue-term="pathname"
                    theme="github-dark" crossorigin="anonymous" async>
                </script>
            </div>
            <ul class="social">
                <li><a href="/about/"><span class="iconfont icon-about"></span></a></li>
                <li><a href="http://github.com/ravelloh" target="_blank" rel="noreferrer"><span
                            class="iconfont icon-github"></span></a></li>
                <li>
                    <a href="http://xeocnet-studio.github.io" target="_blank" rel="noreferrer">
                        <span class="iconfont icon-home">
                            </span>
                    </a>
                </li>
            </ul>
        </section>
        <div class="menu">
            <ul>
                <script type="text/javascript" src="/js/menu.js"></script>
            </ul>
        </div>
        
        <script src="/js/script.js"></script>
        <script src="//instant.page/5.1.0" type="module"
            integrity="sha384-by67kQnR+pyfy8yWP4kPO12fHKRLHZPfEsiSXR8u2IKcTdxD805MGUXBzVPnkLHw"></script>
    </body>

</html>
