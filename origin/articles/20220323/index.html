<article>
    <div id="articles-header">
        <h1><a href="/articles/20220323/">Python实现网络爬虫</a></h1>
        <p class="articles-info">
            <time>2022-03-23</time> • <span class="i_small ri:archive-line"></span> <span class="class"> <a>技术</a> </span> • <span class="i_small ri:t-box-line"></span> <span id="textLength">----字</span> • <span class="i_small ri:search-eye-line"></span> <span id="pageVisitors">---</span>
        </p>
        <p class="articles-tags">
            <span class="i_small ri:price-tag-3-line"></span> <a>Python</a> <a>SPIDER</a>
        </p>
        <hr>
    </div>
    <div id="articles-body">
        <h2>前言</h2>
        <p>
            最近在参与一个数据收集的项目，需要大量获取图像及链接等，用人力显然是完成不过来了，<br> 于是索性就做个爬虫，一劳永逸了。<br> 这里因为项目比较小，对效率要求不大，就选择了使用Python而不是C语言。<br> (也因为Python用起来更省事)<br> 本文所含代码可直接跳转<a class="m" href="#代码">#代码</a>查看
        </p>
        <br>
        <h2>效果</h2> <img class="img" id="img1" src="img1.jpg" loading="lazy" alt="对baidu.com执行扫描的反馈结果">
        <p>
            效果如上图，即输入网页链接，自动提取所含图片链接，<br> 同时自动转化相对路径为绝对路径，方便下载。<br> 最后每行一个print出来，方便统一存储/下载。<br> <br>
        </p>
        <h2>实现方式</h2>
        <p>
            Python在爬虫方面已经十分成熟，这里引用第三方库BeautifulSoup与urllib，若无这些库请下载:
        </p>
        <pre class="codeline">                    <span>pip install bs4</span>
            <span>pip install urllib</span>
        </pre> <em>*命令行执行即可</em> <br>
        <p>
            依赖库准备完后，引用：
        </p>
        <pre class="codeline">                    <span>from urllib.request import urlopen,build_opener,ProxyHandler</span>
            <span>from bs4 import BeautifulSoup as bf</span>
            <span>from urllib import request</span>
            <span>import random</span>
        </pre>
        <p>
            此处引用random以及build_opener与ProxyHandler是为了后续反爬，<br> <del>(毕竟默认UA是Python.Urllib)</del><br> 接着配置UA池与IP代理池，防止被反爬(若项目规模较小可忽略此步)
        </p>
        <pre class="codeline">                    <span># UA</span>
            <span>user_agent_list = [</span>
            <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10.6;rv:2.0.1)Gecko/20100101Firefox/4.0.1",</span>
            <span>    "Mozilla/4.0(compatible;MSIE6.0;WindowsNT5.1)",</span>
            <span>    "Opera/9.80(WindowsNT6.1;U;en)Presto/2.8.131Version/11.11",</span>
            <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11",</span>
            <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1)",</span>
            <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)"</span>
            <span>]</span>
            <span># 随机UA</span>
            <span>headers ={</span>
            <span>    'User-Agent':random.choice(user_agent_list) ## 随机抽取UA</span>
            <span>}</span>
            <span></span>
            <span>ip_list=[</span>
            <span>    '125.120.62.26', ##IP池</span>
            <span>    '66.249.93.118'</span>
            <span>]</span>
            <span></span>
            <span># IP</span>
            <span>ip={</span>
            <span>    'http':random.choice(ip_list) ##随机抽取IP</span>
            <span>}</span>
            <span>link = input("在此输入网址:http://")</span>
            <span>htmlurl = "https://"+str(link) #链接整合，若input中输入了带http头的链接可忽略此行</span>
            <span>req = request.Request(htmlurl,headers=headers) #请求整合</span>
        </pre>
        <p>
            其中，ip_list推荐使用<a href="https://github.com/jhao104/proxy_pool" class="linkline">Github@jhao104/proxy_pool</a>开源的IP代理池。<sup><em>*代码中所列IP均为演示作用，若需应用请自行设置</em></sup><br> 在此就完成了UA与IP的随机分配，反爬基本完成<br> <strong>不过反爬归反爬，也请自觉遵守robot协议，合理利用爬虫</strong> 下一步，发出请求：
        </p>
        <pre class="codeline">                    <span># 用ProxyHandler创建代理ip对象</span>
            <span>pro_han = ProxyHandler(ip)</span>
            <span># 使用build_opener替代urlopen()创建一个对象</span>
            <span>opener = build_opener(pro_han)</span>
            <span># 发送请求</span>
            <span>res = opener.open(req)</span>
        </pre>
        <p>
            到这里为止，整个请求结束，之后用BeautifulSoup解析:<br> <em>*下面已用bs代指beautifulsoup</em>
        </p>
        <pre class="codeline">                <span>obj = bf(res.read(),'html.parser') #解析html</span>
            <span>title = str(obj.head.title) #获取标题</span>
            <span>print("站点标题:",title,"正在查找图片")</span>
            <span>pic_info = obj.find_all('img') #查询img标签</span>
        </pre>
        <p>
            这里也给出不含反爬的请求： (基本同上，唯一的区别是直接用urlopen打开链接)
        </p>
        <pre class="codeline">                <span>html = urlopen("https://"+link)</span>
            <span>obj = bs(html.read(),'html.parser') #解析html</span>
            <span>title = str(obj.head.title) #获取标题</span>
            <span>print("站点标题:",title,"正在查找图片")</span>
            <span>pic_info = obj.find_all('img') #查询img标签</span>
        </pre>
        <p>
            到这里我们已经成功将网页中所含的所有img标签以列表形式存储在了变量pic_info中，<br> 接下来遍历输出即可：
        </p>
        <pre class="codeline">                <span>j = 0 #配置遍历</span>
            <span>for i in pic_info:</span>
            <span>    j += 1</span>
            <span>    pic = str(i['src']) #转为字符串，方便查询</span>
            <span>    if "http" not in pic: #检测http头</span>
            <span>        if "data" in pic: #检测是否为DataURIScheme</span>
            <span>            continue</span>
            <span>        else:</span>
            <span>            if "//" in pic: #格式补全</span>
            <span>                print("http:"+pic) </span>
            <span>            else:</span>
            <span>                if pic[0] == "/": #适配相对路径</span>
            <span>                    print("http://"+link+pic)    </span>
            <span>                else:</span>
            <span>                    print("http://"+link+"/"+pic) </span>
            <span>            </span>
            <span>    else:</span>
            <span>        print(pic) #直接print绝对路径</span>
        </pre>
        <p>
            上图套了四个if-else，作用分别是检测是否有http头、是否为内嵌base64图片、是否以//简写路径、是否使用相对路径，<br> 到这里为止，整个程序就结束了<br> 整个示例程序可分为引用-配置-请求-分析-输出5个部分，<br> 除了爬取图片，也可将上面的<code>pic_info = obj.find_all('img')</code>改成其他标签，<br> 比如改成meta可爬取简介，也可在特定站点内通过zaifind_all内添加对应的class(class_="xxx")及id(id_="xxx")来获取对应标签内的信息，<br> 实现更多功能。
        </p>
        <h2>代码</h2>
        <p>
            完整版
        </p>
        <pre class="codeline">                <span>from urllib.request import urlopen,build_opener,ProxyHandler</span>
            <span>from bs4 import BeautifulSoup as bf</span>
            <span>from urllib import request</span>
            <span>import random</span>
            <span></span>
            <span># UA</span>
            <span>user_agent_list = [</span>
            <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10.6;rv:2.0.1)Gecko/20100101Firefox/4.0.1",</span>
            <span>    "Mozilla/4.0(compatible;MSIE6.0;WindowsNT5.1)",</span>
            <span>    "Opera/9.80(WindowsNT6.1;U;en)Presto/2.8.131Version/11.11",</span>
            <span>    "Mozilla/5.0(Macintosh;IntelMacOSX10_7_0)AppleWebKit/535.11(KHTML,likeGecko)Chrome/17.0.963.56Safari/535.11",</span>
            <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1)",</span>
            <span>    "Mozilla/4.0(compatible;MSIE7.0;WindowsNT5.1;Trident/4.0;SE2.XMetaSr1.0;SE2.XMetaSr1.0;.NETCLR2.0.50727;SE2.XMetaSr1.0)"</span>
            <span>]</span>
            <span># 随机UA</span>
            <span>headers ={</span>
            <span>    'User-Agent':random.choice(user_agent_list)</span>
            <span>}</span>
            <span></span>
            <span>ip_list=[</span>
            <span>    '209.97.171.128',</span>
            <span>    '114.250.25.19',</span>
            <span>    '125.120.62.26',</span>
            <span>    '66.249.93.118',</span>
            <span>    '1.202.113.240',</span>
            <span>]</span>
            <span></span>
            <span># IP</span>
            <span>ip={</span>
            <span>    'http':random.choice(ip_list)</span>
            <span>}</span>
            <span>link = input("在此输入网址:http://")</span>
            <span>htmlurl = "https://"+str(link)</span>
            <span>req = request.Request(htmlurl,headers=headers)</span>
            <span></span>
            <span># 创建代理ip对象</span>
            <span>pro_han = ProxyHandler(ip)</span>
            <span># 使用build_opener创建一个对象</span>
            <span>opener = build_opener(pro_han)</span>
            <span># 发送请求</span>
            <span>res = opener.open(req)</span>
            <span>obj = bf(res.read(),'html.parser') #解析html</span>
            <span>title = str(obj.head.title)</span>
            <span>print("站点标题:",title,"正在查找图片")</span>
            <span>pic_info = obj.find_all('img')</span>
            <span>j = 0 #配置遍历</span>
            <span>for i in pic_info:</span>
            <span>    j += 1</span>
            <span>    pic = str(i['src'])</span>
            <span>    if "http" not in pic:</span>
            <span>        if "data" in pic:</span>
            <span>            continue</span>
            <span>        else:</span>
            <span>            if "//" in pic:</span>
            <span>                print("http:"+pic) </span>
            <span>            else:</span>
            <span>                if pic[0] == "/":</span>
            <span>                    print("http://"+link+pic)    </span>
            <span>                else:</span>
            <span>                    print("http://"+link+"/"+pic) </span>
            <span>            </span>
            <span>    else:</span>
            <span>        print(pic)</span>
        </pre> <br>
        <p>
            基础版
        </p>
        <pre class="codeline">                <span>from urllib.request import urlopen</span>
            <span>from bs4 import BeautifulSoup as bs</span>
            <span>link = input("在此输入网址:http://")</span>
            <span>html = urlopen("https://"+link)</span>
            <span>obj = bs(html.read(),'html.parser') #解析html</span>
            <span>title = str(obj.head.title)</span>
            <span>print("站点标题:",title,"正在查找图片")</span>
            <span>pic_info = obj.find_all('img')</span>
            <span>j = 0 #配置遍历</span>
            <span>for i in pic_info:</span>
            <span>    j += 1</span>
            <span>    pic = str(i['src'])</span>
            <span>    if "http" not in pic:</span>
            <span>        if "data" in pic:</span>
            <span>            continue</span>
            <span>        else:</span>
            <span>            if "//" in pic:</span>
            <span>                print("http:"+pic) </span>
            <span>            else:</span>
            <span>                if pic[0] == "/":</span>
            <span>                    print("http://"+link+pic)    </span>
            <span>                else:</span>
            <span>                    print("http://"+link+"/"+pic) </span>
            <span>            </span>
            <span>    else:</span>
            <span>        print(pic)</span>
        </pre>
        <h3>下载</h3>
        <p>
            此文章共含2个附件，分别对应 基础版 与 完整版 。
        </p>
        <br>
        <p>
            imgspider.py - 0.73kb <a href="https://raw.githubusercontent.com/RavelloH/download/main/code/imgspider.py">预览</a> | <a href="https://ravelloh.github.io/download/code/imgspider.py">下载</a>
        </p>
        <p>
            imgspider-pro.py - 1.76kb <a href="https://raw.githubusercontent.com/RavelloH/download/main/code/imgspider-pro.py">预览</a> | <a href="https://ravelloh.github.io/download/code/imgspider-pro.py">下载</a>
        </p>
    </div>
    <div id="articles-footer">
        <hr>
        <div class="articles-footer-cc">
            <span class="i_small ri:information-line"></span> 原创内容使用 <a href="/help#分享协议"> <span class="i_small ri:creative-commons-line"></span><span class="i_small ri:creative-commons-nc-line"></span><span class="i_small ri:creative-commons-nd-line"></span>知识共享 署名-非商业性使用-相同方式共享 4.0 (CC BY-NC-ND 4.0) </a> 协议授权。转载请注明出处。
        </div>
        <div id="blockchain-data"></div>
        <div id="more-articles">
            <div id="previous" onclick="pjaxLoad('${previousArticlesUrl}')">
                <b><span class="i_small ri:arrow-left-s-line"></span> 上一篇</b><br> <span class="one-line">正在加载中...</span>
            </div>
            <div id="next" onclick="pjaxLoad('${nextArticlesUrl}')">
                <b>下一篇 <span class="i_small ri:arrow-right-s-line"></span></b><br> <span class="one-line">正在加载中...</span>
            </div>
        </div>
        <br><br>
        <div id="tcomment">
            <div class="info center">
                <span class="i_small ri:download-cloud-line"></span> 正在加载评论...
            </div>
        </div>
    </div>
</article>